{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969df29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('cleaned_metadata.csv')\n",
    "## Delete empty rows (In case I missed parsing a row)\n",
    "test = test.dropna()\n",
    "print(\"\\n ** raw data **\\n\")\n",
    "print(test.head())\n",
    "print(\"\\n ** data shape **\\n\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lower case\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join(x.lower()for x in x.split()))\n",
    "## remove tabulation and punctuation\n",
    "test['description'] = test['description'].str.replace('[^\\w\\s]',' ')\n",
    "## digits\n",
    "test['description'] = test['description'].str.replace('\\d+', '')\n",
    "\n",
    "#remove stop words\n",
    "stop = stopwords.words('english')\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "## lemmatization\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "print(\"Preprocessed data: \\n\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6020b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## jda stands for job description aggregated\n",
    "jda = test.groupby(['job_title']).sum().reset_index()\n",
    "print(\"Aggregated job descriptions: \\n\")\n",
    "print(jda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize data\n",
    "jobs_list = jda.job_title.unique().tolist()\n",
    "for job in jobs_list:\n",
    "\n",
    "    # Start with one review:\n",
    "    text = jda[jda.job_title == job].iloc[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d315ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete more stop words\n",
    "other_stop_words = ['stopwords that you want to delete']\n",
    "\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in other_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820abc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting text to features \n",
    "vectorizer = TfidfVectorizer()\n",
    "#Tokenize and build vocabulary\n",
    "X = vectorizer.fit_transform(test.description)\n",
    "y = test.job_title\n",
    "\n",
    "# split data into 80% training and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109) \n",
    "print(\"train data shape: \",X_train.shape)\n",
    "print(\"test data shape: \",X_test.shape)\n",
    "# Fit model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "## Predict\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a153500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the predictions\n",
    "print(\"Accuracy score is: \",accuracy_score(y_test, y_predicted))\n",
    "print(\"Classes: (to help read Confusion Matrix)\\n\", clf.classes_)\n",
    "print(\"Confusion Matrix: \")\n",
    "\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "technical_skills = ['python', 'c','r', 'c++','java','hadoop','scala','pandas','spark','scikit-learn',\n",
    "                    'numpy','php','css','mongdb','nltk','fastai' , 'keras', 'pytorch','tensorflow',\n",
    "                   'linux','Ruby','JavaScript','django','react','reactjs','ai','ui','tableau']\n",
    "feature_array = vectorizer.get_feature_names()\n",
    "# number of overall model features\n",
    "features_numbers = len(feature_array)\n",
    "## max sorted features number\n",
    "n_max = int(features_numbers * 0.1)\n",
    "\n",
    "##initialize output dataframe\n",
    "output = pd.DataFrame()\n",
    "for i in range(0,len(clf.classes_)):\n",
    "    print(\"\\n****\" ,clf.classes_[i],\"****\\n\")\n",
    "    class_prob_indices_sorted = clf.feature_log_prob_[i, :].argsort()[::-1]\n",
    "    raw_skills = np.take(feature_array, class_prob_indices_sorted[:n_max])\n",
    "    print(\"list of unprocessed skills :\")\n",
    "    print(raw_skills)\n",
    "    \n",
    "    ## Extract technical skills\n",
    "    top_technical_skills= list(set(technical_skills).intersection(raw_skills))[:6]\n",
    "    #print(\"Top technical skills\",top_technical_skills)\n",
    "    \n",
    "    ## Extract adjectives\n",
    "    \n",
    "    # Delete technical skills from raw skills list\n",
    "    ## At this steps, raw skills list doesnt contain the technical skills\n",
    "    #raw_skills = [x for x in raw_skills if x not in top_technical_skills]\n",
    "    #raw_skills = list(set(raw_skills) - set(top_technical_skills))\n",
    "\n",
    "    # transform list to string\n",
    "    txt = \" \".join(raw_skills)\n",
    "    blob = TextBlob(txt)\n",
    "    #top 6 adjective\n",
    "    top_adjectives = [w for (w, pos) in TextBlob(txt).pos_tags if pos.startswith(\"JJ\")][:6]\n",
    "    #print(\"Top 6 adjectives: \",top_adjectives)\n",
    "    \n",
    "    output = output.append({'job_title':clf.classes_[i],\n",
    "                        'technical_skills':top_technical_skills,\n",
    "                        'soft_skills':top_adjectives },\n",
    "                       ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa613d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
